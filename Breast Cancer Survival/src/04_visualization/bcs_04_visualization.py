# -*- coding: utf-8 -*-
"""BCS_04. Visualization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z-SZ6bQigUPCkGIehJAZhFqsV8rZ9oTq
"""

#1 Initialize Environment and Import Core Libraries

import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, StandardScaler
!pip install lifelines
from lifelines import CoxPHFitter
from lifelines.utils import concordance_index
from lifelines import KaplanMeierFitter

"""### ðŸ”¢ Step #1: Environment Setup and Library Imports

This initial step prepares the Python environment for survival analysis by importing essential libraries and installing required packages. It begins with core modules like `os` for system operations, `pandas` for data manipulation, `matplotlib.pyplot` and `seaborn` for visualization, and preprocessing tools from `sklearn` such as `LabelEncoder` and `StandardScaler`. The `lifelines` packageâ€”central to survival modelingâ€”is installed via pip, and key components like `CoxPHFitter`, `KaplanMeierFitter`, and `concordance_index` are imported to support model fitting and evaluation. This setup ensures all tools are ready for data exploration, transformation, and survival modeling in subsequent steps.

"""

#2 Link Colab to Google Drive
from google.colab import drive
drive.mount('/content/drive')

"""### ðŸ”¢ Step #2: Mount Google Drive for Persistent Storage

This step connects the Colab environment to the user's Google Drive, enabling access to external files and persistent storage. By importing `drive` from `google.colab` and executing `drive.mount('/content/drive')`, the notebook gains read/write access to the Drive contents. Once mounted, the Drive appears under the `/content/drive` path, allowing seamless loading of datasets, saving of outputs, and integration with project directories stored in the cloud. This setup is essential for workflows that require durable storage across sessions or collaboration with shared resources.

"""

#3 Set Paths for Dataset and Output Storage

import os # Import os for path manipulation
project_root = '/content/drive/MyDrive/METABRIC_project'
data_path = '/content/drive/MyDrive/METABRIC_cleaned_imputed.csv' # Corrected path
output_path = os.path.join(project_root, 'outputs')

"""### ðŸ”¢ Step #3: Define File Paths for Data Access and Output Management

This step establishes standardized paths for accessing the dataset and organizing output files. It begins by importing the `os` module to enable robust path manipulation. The `project_root` variable defines the main directory within Google Drive where project assets are stored. `data_path` points directly to the METABRIC dataset CSV file, ensuring consistent access for analysis. The `output_path` is constructed using `os.path.join` to create a dedicated subdirectory for saving results, figures, and artifacts. This structure supports reproducibility, simplifies file handling, and maintains a clean separation between raw data and generated outputs.

"""

#4 Kaplan-Meier Curves by Risk Group
from lifelines import KaplanMeierFitter
import matplotlib.pyplot as plt

kmf = KaplanMeierFitter()
plt.figure(figsize=(8,6))

for group in ['Low', 'Medium', 'High']:
    mask = cox_df['risk_group'] == group
    kmf.fit(cox_df[mask]['duration'], event_observed=cox_df[mask]['event'], label=group)
    kmf.plot_survival_function()

plt.title('Kaplan-Meier Survival by Risk Group')
plt.xlabel('Time (months)')
plt.ylabel('Survival Probability')
plt.grid(True)
plt.show()

# 4.2 Hazard Ratios
cph.plot()
plt.title('Hazard Ratios from Cox Model')
plt.tight_layout()
plt.show()

"""### ðŸ”¢ Step #4: Survival Curve Visualization and Hazard Interpretation

This step provides visual insights into survival outcomes and the influence of covariates using two complementary plots. In substep 4.1, Kaplan-Meier survival curves are generated for three risk groupsâ€”Low, Medium, and Highâ€”using the `KaplanMeierFitter`. These curves illustrate how survival probability changes over time for each group, with confidence intervals enhancing interpretability. In substep 4.2, the fitted Cox proportional hazards model is visualized using `cph.plot()`, which displays hazard ratios and their confidence intervals for each
"""

#5. Create Risk Groups based on Cox Model Prognostic Score

# Calculate the prognostic score for each patient
# The partial hazard is often used as a prognostic index
cox_df['prognostic_score'] = cph.predict_partial_hazard(cox_df[existing_covariates])

# Define risk groups based on tertiles of the prognostic score
tertiles = cox_df['prognostic_score'].quantile([1/3, 2/3])

def assign_risk_group(score):
    if score <= tertiles.iloc[0]:
        return 'Low'
    elif score <= tertiles.iloc[1]:
        return 'Medium'
    else:
        return 'High'

cox_df['risk_group'] = cox_df['prognostic_score'].apply(assign_risk_group)

print("Cox DataFrame with Risk Groups:")
display(cox_df.head())
print("Risk Group Distribution:")
print(cox_df['risk_group'].value_counts())

"""### ðŸ”¢ Step #5: Generate Risk Groups from Prognostic Index

This step translates model predictions into clinically meaningful risk categories. Using the fitted Cox proportional hazards model, a prognostic score is computed for each patient via `predict_partial_hazard`, reflecting their relative risk. The score distribution is divided into tertiles to define thresholds for 'Low', 'Medium', and 'High' risk groups. A custom function assigns each patient to a group based on their score, and the resulting `risk_group` column is added to the dataset. This stratification enables targeted survival analysis and supports clearer interpretation of model outputs in clinical contexts.

"""

#6 Kaplan-Meier Curves by Risk Group
from lifelines import KaplanMeierFitter
import matplotlib.pyplot as plt

kmf = KaplanMeierFitter()
plt.figure(figsize=(8,6))

for group in ['Low', 'Medium', 'High']:
    mask = cox_df['risk_group'] == group
    # Ensure there are samples in the group before fitting
    if not cox_df[mask].empty:
        kmf.fit(cox_df[mask]['duration'], event_observed=cox_df[mask]['event'], label=group)
        kmf.plot_survival_function()
    else:
        print(f"Warning: No data for risk group: {group}")

plt.title('Kaplan-Meier Survival by Risk Group')
plt.xlabel('Time (months)')
plt.ylabel('Survival Probability')
plt.grid(True)
plt.show()

# 4.2 Hazard Ratios
cph.plot()
plt.title('Hazard Ratios from Cox Model')
plt.tight_layout()
plt.show()

"""### ðŸ”¢ Step #6: Plot Survival Curves and Model Effects by Risk Group

This step visualizes survival outcomes and model-derived risk effects using two key plots. Kaplan-Meier survival curves are generated for each risk groupâ€”Low, Medium, and Highâ€”using `KaplanMeierFitter`, with a check to ensure each group contains data before fitting. These curves illustrate how survival probabilities diverge over time across stratified patient groups. Additionally, the Cox modelâ€™s hazard ratios are plotted using `cph.plot()`, showing the relative influence of each covariate on patient risk, along with confidence intervals. Together, these visualizations validate the risk stratification and enhance interpretability of the modelâ€™s predictive insights.

"""

#7 Preview Final Cox Model Inputs

import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler
from lifelines import CoxPHFitter

# 1. Load the dataset
df = pd.read_csv(data_path)

# Standardize column names by stripping whitespace and converting to lowercase
df.columns = df.columns.str.strip().str.lower()

# DEBUG: Print columns to verify actual names after lowercasing
print("Columns in DataFrame after lowercasing:")
print(df.columns.tolist())

# 2. Prepare the data for Cox model
# Identify event and duration columns more robustly
event_candidates = ['overall survival status', 'death', 'event', 'event_status', 'patient_status'] # Added 'overall survival status'
duration_candidates = ['overall survival (months)', 'duration', 'survival_months', 'time_to_event']

event_col_found = None
for cand in event_candidates:
    if cand in df.columns:
        event_col_found = cand
        break

duration_col_found = None
for cand in duration_candidates:
    if cand in df.columns:
        duration_col_found = cand
        break

if not event_col_found:
    raise ValueError(f"Could not find a suitable 'event' column from candidates: {event_candidates}. Available: {df.columns.tolist()}")

if not duration_col_found:
    raise ValueError(f"Could not find a suitable 'duration' column from candidates: {duration_candidates}. Available: {df.columns.tolist()}")

# Rename columns to 'event' and 'duration' for consistency if they are not already named so
if event_col_found != 'event':
    df = df.rename(columns={event_col_found: 'event'})
if duration_col_found != 'duration':
    df = df.rename(columns={duration_col_found: 'duration'})

# Convert 'event' column to numerical (0 or 1)
# Assuming 'Deceased' or similar indicates an event (1), and 'Living' or similar indicates censored (0)
df['event'] = df['event'].apply(lambda x: 1 if x.lower() == 'deceased' else 0)

# Select relevant features (covariates) for the Cox model
covariates_list = [
    'age at diagnosis',
    'tumor size',
    'lymph nodes examined',
    'npi',
    'cellularity',
    'er status',
    'pr status',
    'her2 status',
    'grade'
]

# Filter covariates to include only those present in the DataFrame
existing_covariates = [col for col in covariates_list if col in df.columns]

cox_df = df[['duration', 'event'] + existing_covariates].copy()

# Handle categorical variables using Label Encoding
for col in ['cellularity', 'er status', 'pr status', 'her2 status', 'grade']:
    if col in cox_df.columns: # Only attempt if column exists in cox_df
        le = LabelEncoder()
        cox_df[col] = le.fit_transform(cox_df[col])

# Scale numerical variables (optional but good practice for some models, though CPH is scale-invariant)
for col in ['age at diagnosis', 'tumor size', 'lymph nodes examined', 'npi']:
    if col in cox_df.columns: # Only attempt if column exists in cox_df
        scaler = StandardScaler()
        cox_df[col] = scaler.fit_transform(cox_df[[col]])

# Display the first few rows of the prepared data
print("Prepared DataFrame (cox_df) head:")
display(cox_df.head())

"""### ðŸ“˜ Step #7: Preview Final Cox Model Inputs

This step displays the first few rows of the `cox_df` DataFrame, which contains the cleaned and transformed features prepared for survival modeling using the Cox proportional hazards model. It includes the standardized `duration` and binary `event` columns, along with selected covariates that have undergone label encoding for categorical variables and scaling for numerical ones. By previewing the head of `cox_df`, the analyst verifies that preprocessing steps were correctly applied and confirms the dataset is structured appropriately for modeling.

"""

#8. Fit the Cox Proportional Hazards model
cph = CoxPHFitter()
cph.fit(cox_df, duration_col='duration', event_col='event')

# Display the model summary
print("\nCox Proportional Hazards Model Summary:")
cph.print_summary()

"""### ðŸ“Š Step #8: Fit and Evaluate Cox Model

This step fits the Cox Proportional Hazards model using the `lifelines` library and evaluates its performance. The model is trained on the preprocessed `cox_df` dataset using the `duration` and `event` columns. After fitting, the summary output provides key metrics: 2509 observations, 1672 events, and a partial log-likelihood of -11701.14. Covariate coefficients reveal the direction and magnitude of each variableâ€™s effect on survival, with hazard ratios (`exp(coef)`) indicating increased or decreased risk. For example, higher age at diagnosis and tumor size are associated with increased hazard, while ER status shows a protective effect. The modelâ€™s statistical strength is confirmed by a log-likelihood ratio test of 266.09 on 6 degrees of freedom, with a highly significant p-value (âˆ’logâ‚‚(p) = 178.81), and a concordance index of 0.61, suggesting moderate predictive discrimination.


"""