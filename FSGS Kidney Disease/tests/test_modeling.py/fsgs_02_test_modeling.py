# -*- coding: utf-8 -*-
"""FSGS_02_test_modeling

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xWuL4UnKi7ZbuTkHXxReItCSvBD5sMND

ðŸ“ 02_test_modeling.py
"""

#1 Mount Google Drive for File Access

from google.colab import drive
drive.mount('/content/drive')

"""**Step#1:** This initial step establishes access to files stored in Google Drive by mounting the drive within the Google Colab environment. It begins by importing the drive module from google.colab, then uses drive.mount('/content/drive') to link the user's Google Drive to the Colab session. Once mounted, the contents of the drive become accessible under the /content/drive path, allowing seamless file reading and writing during analysis. This setup is essential for workflows that rely on external datasets, scripts, or outputs stored in Drive."""

#2 Import ML Tools for Modeling and Evaluation

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import pandas as pd

"""**Step#2:** This step sets up the essential machine learning tools needed for modeling and evaluation. It imports functions from scikit-learn for splitting datasets (train_test_split), building a logistic regression model (LogisticRegression), and assessing model performance (accuracy_score). Additionally, it imports pandas (pd) for data manipulation and analysis. These imports lay the groundwork for the entire modeling pipeline, enabling structured data handling, model training, and performance evaluation in subsequent steps."""

#3

def test_model_training():
    df = pd.read_csv('/content/drive/MyDrive/fsgs_Kidney_Disease_study/data/processed/fsgs_dataset_cleaned.csv')
    X = df.drop(columns=['target'])
    y = df['target']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    model = LogisticRegression(max_iter=1000)
    model.fit(X_train, y_train)
    assert hasattr(model, "coef_"), "Model training failed"

"""**Step#3:** This step defines a test function to validate the training process of a logistic regression model using a cleaned dataset related to FSGS kidney disease. It begins by loading the dataset from Google Drive, then separates the features (X) from the target variable (y). The data is split into training and testing sets using an 80/20 ratio. A logistic regression model is instantiated with a high iteration limit to ensure convergence, and then trained on the training data. The final line asserts that the model has successfully learned by checking for the presence of the coef_ attribute, which stores the learned coefficients."""

#4 Evaluate Model Accuracy Threshold

def test_model_accuracy():
    df = pd.read_csv('/content/drive/MyDrive/fsgs_Kidney_Disease_study/data/processed/fsgs_dataset_cleaned.csv')
    X = df.drop(columns=['target'])
    y = df['target']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    model = LogisticRegression(max_iter=1000)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    assert acc > 0.7, f"Model accuracy too low: {acc}"

"""**Step#4:**  defines a test function called test_model_accuracy() that evaluates the performance of a logistic regression model trained on the cleaned FSGS kidney disease dataset. The function begins by loading the dataset and separating the features (x) from the target variable (y). It then splits the data into training and testing sets using an 80/20 ratio with a fixed random seed for reproducibility. A logistic regression model is instantiated with a high iteration limit (max_iter=1000) and trained on the training data. Predictions are made on the test set, and the accuracy score is computed. The function asserts that the model achieves an accuracy greater than 0.7, raising an error with the actual score if the threshold is not metâ€”serving as a basic quality gate for model performance."""