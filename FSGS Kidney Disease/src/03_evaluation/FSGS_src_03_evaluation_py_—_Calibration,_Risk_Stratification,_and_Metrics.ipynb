{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "src/03_evaluation.py — Calibration, Risk Stratification, and Metrics"
      ],
      "metadata": {
        "id": "9qM1belgtADA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rwHP49xs6Eo",
        "outputId": "7a3634d3-12e8-49f0-f042-d8c83b6cde2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#1 Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 Set paths\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score, brier_score_loss, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.calibration import calibration_curve"
      ],
      "metadata": {
        "id": "unb0XOV5tF4g"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "!pip install lifelines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCS5L6yhtGFY",
        "outputId": "d0fe2a68-989b-4d4d-d2c8-18a621bb3938"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lifelines\n",
            "  Downloading lifelines-0.30.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from lifelines) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from lifelines) (1.16.3)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.12/dist-packages (from lifelines) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.12/dist-packages (from lifelines) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.12/dist-packages (from lifelines) (1.8.0)\n",
            "Collecting autograd-gamma>=0.3 (from lifelines)\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting formulaic>=0.2.2 (from lifelines)\n",
            "  Downloading formulaic-1.2.1-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: narwhals>=1.17 in /usr/local/lib/python3.12/dist-packages (from formulaic>=0.2.2->lifelines) (2.15.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from formulaic>=0.2.2->lifelines) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.12/dist-packages (from formulaic>=0.2.2->lifelines) (2.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0->lifelines) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1->lifelines) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1->lifelines) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.17.0)\n",
            "Downloading lifelines-0.30.0-py3-none-any.whl (349 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic-1.2.1-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.3/117.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: autograd-gamma\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=f311e2768f42af1ee371f663827e0069dcf0b318663c43a80b3f3957754e73f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/37/21/0a719b9d89c635e89ff24bd93b862882ad675279552013b2fb\n",
            "Successfully built autograd-gamma\n",
            "Installing collected packages: interface-meta, autograd-gamma, formulaic, lifelines\n",
            "Successfully installed autograd-gamma-0.5.0 formulaic-1.2.1 interface-meta-1.3.0 lifelines-0.30.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4 Define paths\n",
        "project_root = '/content/drive/MyDrive/fsgs_Kidney_Disease_study'\n",
        "data_path = os.path.join(project_root, 'data', 'processed', 'fsgs_dataset_cleaned.csv')\n",
        "output_path = os.path.join(project_root, 'outputs', 'evaluation')\n",
        "os.makedirs(output_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "F35EoZjPtTFH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5 Load stratified dataset\n",
        "df = pd.read_csv(data_path)"
      ],
      "metadata": {
        "id": "BVjaMOdjtTQR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assume 'risk_score' and 'risk_group' already exist from modeling step. If not, load model and compute them here"
      ],
      "metadata": {
        "id": "xV4r-672t5J2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Calibration Curve\n",
        "\n",
        "def plot_calibration_curve(y_true, y_prob, n_bins=10):\n",
        "    prob_true, prob_pred = calibration_curve(y_true, y_prob, n_bins=n_bins)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(prob_pred, prob_true, marker='o', label='Calibration Curve')\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect Calibration')\n",
        "    plt.xlabel('Predicted Probability')\n",
        "    plt.ylabel('Observed Probability')\n",
        "    plt.title('Calibration Curve')\n",
        "    plt.legend()\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_path, 'calibration_curve.png'))\n",
        "    plt.show()\n",
        "\n",
        "plot_calibration_curve(df['outcome_dialysis_y_n'], df['risk_score'])"
      ],
      "metadata": {
        "id": "sWlb2TvZtTdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7. Risk Stratification Summary\n",
        "\n",
        "def summarize_risk_groups(df, time_col='survival_time', event_col='event'):\n",
        "    summary = df.groupby('risk_group', observed=False)[[time_col, event_col]].agg(['count', 'mean', 'median'])\n",
        "    print(\"Risk Group Summary:\")\n",
        "    print(summary)\n",
        "    summary.to_csv(os.path.join(output_path, 'risk_group_summary.csv'))\n",
        "\n",
        "# If 'risk_group' column does not exist, create it.\n",
        "# Assuming 'FU_ESRD' can be used as a proxy for risk score for stratification.\n",
        "if 'risk_group' not in df.columns:\n",
        "    # Creating 4 risk groups based on quartiles of 'FU_ESRD'\n",
        "    df['risk_group'] = pd.qcut(df['FU_ESRD'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
        "\n",
        "# Call the function with appropriate column names from the loaded dataframe\n",
        "# Assuming 'FU_ESRD' is the time to event and 'outcome_dialysis_y_n' is the event indicator.\n",
        "summarize_risk_groups(df, time_col='FU_ESRD', event_col='outcome_dialysis_y_n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj6_NrUFxTNS",
        "outputId": "5fa58d31-c483-46f1-de87-9c3d44c85005"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Risk Group Summary:\n",
            "           FU_ESRD                   outcome_dialysis_y_n                 \n",
            "             count       mean median                count      mean median\n",
            "risk_group                                                                \n",
            "Q1             147   2.783401   2.81                  147  0.265306    0.0\n",
            "Q2             220   6.458636   6.83                  220  0.104545    0.0\n",
            "Q3              67   8.160299   8.08                   67  0.149254    0.0\n",
            "Q4             145  14.488069  13.75                  145  0.110345    0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8 Metrics: Concordance Index, AUC, Brier Score\n",
        "\n",
        "from lifelines.utils import concordance_index\n",
        "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
        "\n",
        "def evaluate_model(df, y_true_col, y_time_col, risk_score_col):\n",
        "    y_true = df[y_true_col]\n",
        "    y_time = df[y_time_col]\n",
        "    risk_scores = df[risk_score_col]\n",
        "\n",
        "    # Concordance Index\n",
        "    c_index = concordance_index(y_time, -risk_scores, y_true)\n",
        "    print(f\"Concordance Index: {c_index:.3f}\")\n",
        "\n",
        "    # AUC (if binary classification)\n",
        "    auc = roc_auc_score(y_true, risk_scores)\n",
        "    print(f\"AUC: {auc:.3f}\")\n",
        "\n",
        "    # Brier Score\n",
        "    brier = brier_score_loss(y_true, risk_scores)\n",
        "    print(f\"Brier Score: {brier:.3f}\")\n",
        "\n",
        "    return c_index, auc, brier"
      ],
      "metadata": {
        "id": "wjed4-YnxTba"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9 Create a dummy risk_score for demonstration (replace with actual model predictions in a real scenario)\n",
        "# Inverting and scaling FU_ESRD: lower FU_ESRD means higher risk, so we want higher risk_score.\n",
        "df['risk_score'] = 1 / (1 + df['FU_ESRD'])\n",
        "\n",
        "# Call the evaluate_model function\n",
        "c_index, auc, brier = evaluate_model(df, y_true_col='outcome_dialysis_y_n', y_time_col='FU_ESRD', risk_score_col='risk_score')\n",
        "\n",
        "print(f\"\\nEvaluation Metrics using dummy risk scores:\")\n",
        "print(f\"  Concordance Index: {c_index:.3f}\")\n",
        "print(f\"  AUC: {auc:.3f}\")\n",
        "print(f\"  Brier Score: {brier:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Layb1NSZxTow",
        "outputId": "34d28675-fcd1-4cb3-f979-15074c359009"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Concordance Index: 1.000\n",
            "AUC: 0.644\n",
            "Brier Score: 0.129\n",
            "\n",
            "Evaluation Metrics using dummy risk scores:\n",
            "  Concordance Index: 1.000\n",
            "  AUC: 0.644\n",
            "  Brier Score: 0.129\n"
          ]
        }
      ]
    }
  ]
}