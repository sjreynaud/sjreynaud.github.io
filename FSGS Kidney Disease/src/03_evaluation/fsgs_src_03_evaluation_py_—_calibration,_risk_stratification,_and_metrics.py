# -*- coding: utf-8 -*-
"""FSGS_src/03_evaluation.py — Calibration, Risk Stratification, and Metrics

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/179UOQ-MpM7Qv-7uMXO33t9d0IRCmtNeO

src/03_evaluation.py — Calibration, Risk Stratification, and Metrics
"""

#1 Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

#2 Set paths
import os
import pandas as pd
from sklearn.metrics import roc_auc_score, brier_score_loss, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.calibration import calibration_curve

#3
!pip install lifelines

#4 Define paths
project_root = '/content/drive/MyDrive/fsgs_Kidney_Disease_study'
data_path = os.path.join(project_root, 'data', 'processed', 'fsgs_dataset_cleaned.csv')
output_path = os.path.join(project_root, 'outputs', 'evaluation')
os.makedirs(output_path, exist_ok=True)

#5 Load stratified dataset
df = pd.read_csv(data_path)

"""Assume 'risk_score' and 'risk_group' already exist from modeling step. If not, load model and compute them here"""

#6. Calibration Curve

def plot_calibration_curve(y_true, y_prob, n_bins=10):
    prob_true, prob_pred = calibration_curve(y_true, y_prob, n_bins=n_bins)
    plt.figure(figsize=(8, 6))
    plt.plot(prob_pred, prob_true, marker='o', label='Calibration Curve')
    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect Calibration')
    plt.xlabel('Predicted Probability')
    plt.ylabel('Observed Probability')
    plt.title('Calibration Curve')
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.tight_layout()
    plt.savefig(os.path.join(output_path, 'calibration_curve.png'))
    plt.show()

plot_calibration_curve(df['outcome_dialysis_y_n'], df['risk_score'])

#7. Risk Stratification Summary

def summarize_risk_groups(df, time_col='survival_time', event_col='event'):
    summary = df.groupby('risk_group', observed=False)[[time_col, event_col]].agg(['count', 'mean', 'median'])
    print("Risk Group Summary:")
    print(summary)
    summary.to_csv(os.path.join(output_path, 'risk_group_summary.csv'))

# If 'risk_group' column does not exist, create it.
# Assuming 'FU_ESRD' can be used as a proxy for risk score for stratification.
if 'risk_group' not in df.columns:
    # Creating 4 risk groups based on quartiles of 'FU_ESRD'
    df['risk_group'] = pd.qcut(df['FU_ESRD'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])

# Call the function with appropriate column names from the loaded dataframe
# Assuming 'FU_ESRD' is the time to event and 'outcome_dialysis_y_n' is the event indicator.
summarize_risk_groups(df, time_col='FU_ESRD', event_col='outcome_dialysis_y_n')

#8 Metrics: Concordance Index, AUC, Brier Score

from lifelines.utils import concordance_index
from sklearn.metrics import roc_auc_score, brier_score_loss

def evaluate_model(df, y_true_col, y_time_col, risk_score_col):
    y_true = df[y_true_col]
    y_time = df[y_time_col]
    risk_scores = df[risk_score_col]

    # Concordance Index
    c_index = concordance_index(y_time, -risk_scores, y_true)
    print(f"Concordance Index: {c_index:.3f}")

    # AUC (if binary classification)
    auc = roc_auc_score(y_true, risk_scores)
    print(f"AUC: {auc:.3f}")

    # Brier Score
    brier = brier_score_loss(y_true, risk_scores)
    print(f"Brier Score: {brier:.3f}")

    return c_index, auc, brier

#9 Create a dummy risk_score for demonstration (replace with actual model predictions in a real scenario)
# Inverting and scaling FU_ESRD: lower FU_ESRD means higher risk, so we want higher risk_score.
df['risk_score'] = 1 / (1 + df['FU_ESRD'])

# Call the evaluate_model function
c_index, auc, brier = evaluate_model(df, y_true_col='outcome_dialysis_y_n', y_time_col='FU_ESRD', risk_score_col='risk_score')

print(f"\nEvaluation Metrics using dummy risk scores:")
print(f"  Concordance Index: {c_index:.3f}")
print(f"  AUC: {auc:.3f}")
print(f"  Brier Score: {brier:.3f}")