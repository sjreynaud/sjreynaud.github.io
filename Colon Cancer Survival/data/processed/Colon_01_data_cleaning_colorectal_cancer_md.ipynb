{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1-4.** Mount Google Drive and load the dataset"
      ],
      "metadata": {
        "id": "-Hzlm8TXfO8F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUE2gELsZziM",
        "outputId": "8a65205a-d10e-4905-fcb9-745050776e3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#1 Initialize Google Drive Integration\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#1** establishes access to your Google Drive within the Colab environment. The code imports the google.colab.drive module and mounts your Drive at the directory /content/drive, which allows Colab to read and write files just as if they were stored locally. Once mounted, any datasets, scripts, or outputs saved in your Drive become available for the rest of your workflow, ensuring smooth integration between cloud storage and your analysis pipeline."
      ],
      "metadata": {
        "id": "qidZl-byj6-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2 Load pandas Library for Data Handling\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "WnMI1lk-ePaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#2** loads the pandas library, which is one of the core tools for data manipulation and analysis in Python. Importing it at the beginning of your workflow ensures that you can create DataFrames, read files, clean datasets, and perform transformations throughout the rest of your pipeline. The alias pd is a widely accepted convention that keeps your code concise and readable, especially when calling pandas functions repeatedly."
      ],
      "metadata": {
        "id": "F4erAIUPkqr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#3 Load Primary Dataset into DataFrame\n",
        "df = pd.read_csv('/content/drive/MyDrive/colorectal_cancer_prediction.csv')"
      ],
      "metadata": {
        "id": "RWcqN5Keeb7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#3** brings your dataset into the workflow by reading a CSV file from your Google Drive and loading it into a pandas DataFrame. This action transforms the raw file into a structured, table‑like object (df) that you can filter, clean, explore, and analyze throughout the rest of your pipeline. By specifying the full path to the file, the notebook knows exactly where to find your data, ensuring a smooth transition from storage to analysis."
      ],
      "metadata": {
        "id": "_LinLOkUlpIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#4 Explore Dataset Structure and Metadata\n",
        "\n",
        "print(df.shape)      # dimensions\n",
        "print(df.head())     # preview first rows\n",
        "print(df.info())     # column types + missing values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMZRTSc6eb6d",
        "outputId": "b708f560-5354-414a-a6fe-49708aa30619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(89945, 30)\n",
            "   Patient_ID  Age  Gender   Race         Region Urban_or_Rural  \\\n",
            "0           1   71    Male  Other         Europe          Urban   \n",
            "1           2   34  Female  Black  North America          Urban   \n",
            "2           3   80  Female  White  North America          Urban   \n",
            "3           4   40    Male  Black  North America          Rural   \n",
            "4           5   43  Female  White         Europe          Urban   \n",
            "\n",
            "  Socioeconomic_Status Family_History Previous_Cancer_History  \\\n",
            "0               Middle            Yes                      No   \n",
            "1               Middle             No                      No   \n",
            "2               Middle             No                      No   \n",
            "3                  Low             No                      No   \n",
            "4                 High            Yes                      No   \n",
            "\n",
            "  Stage_at_Diagnosis  ... Insurance_Coverage Time_to_Diagnosis  \\\n",
            "0                III  ...                Yes           Delayed   \n",
            "1                  I  ...                 No            Timely   \n",
            "2                III  ...                Yes            Timely   \n",
            "3                  I  ...                Yes           Delayed   \n",
            "4                III  ...                 No           Delayed   \n",
            "\n",
            "  Treatment_Access Chemotherapy_Received  Radiotherapy_Received  \\\n",
            "0             Good                   Yes                     No   \n",
            "1             Good                    No                    Yes   \n",
            "2          Limited                    No                    Yes   \n",
            "3          Limited                   Yes                     No   \n",
            "4             Good                   Yes                     No   \n",
            "\n",
            "  Surgery_Received Follow_Up_Adherence Survival_Status Recurrence  \\\n",
            "0               No                Good        Survived         No   \n",
            "1              Yes                Poor        Deceased         No   \n",
            "2              Yes                Good        Survived         No   \n",
            "3              Yes                Poor        Deceased         No   \n",
            "4              Yes                Poor        Deceased        Yes   \n",
            "\n",
            "  Time_to_Recurrence  \n",
            "0                 16  \n",
            "1                 28  \n",
            "2                 26  \n",
            "3                 44  \n",
            "4                 20  \n",
            "\n",
            "[5 rows x 30 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 89945 entries, 0 to 89944\n",
            "Data columns (total 30 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   Patient_ID               89945 non-null  int64  \n",
            " 1   Age                      89945 non-null  int64  \n",
            " 2   Gender                   89945 non-null  object \n",
            " 3   Race                     89945 non-null  object \n",
            " 4   Region                   89945 non-null  object \n",
            " 5   Urban_or_Rural           89945 non-null  object \n",
            " 6   Socioeconomic_Status     89945 non-null  object \n",
            " 7   Family_History           89945 non-null  object \n",
            " 8   Previous_Cancer_History  89945 non-null  object \n",
            " 9   Stage_at_Diagnosis       89945 non-null  object \n",
            " 10  Tumor_Aggressiveness     89945 non-null  object \n",
            " 11  Colonoscopy_Access       89945 non-null  object \n",
            " 12  Screening_Regularity     89945 non-null  object \n",
            " 13  Diet_Type                89945 non-null  object \n",
            " 14  BMI                      89945 non-null  float64\n",
            " 15  Physical_Activity_Level  89945 non-null  object \n",
            " 16  Smoking_Status           89945 non-null  object \n",
            " 17  Alcohol_Consumption      89945 non-null  object \n",
            " 18  Red_Meat_Consumption     89945 non-null  object \n",
            " 19  Fiber_Consumption        89945 non-null  object \n",
            " 20  Insurance_Coverage       89945 non-null  object \n",
            " 21  Time_to_Diagnosis        89945 non-null  object \n",
            " 22  Treatment_Access         89945 non-null  object \n",
            " 23  Chemotherapy_Received    89945 non-null  object \n",
            " 24  Radiotherapy_Received    89945 non-null  object \n",
            " 25  Surgery_Received         89945 non-null  object \n",
            " 26  Follow_Up_Adherence      89945 non-null  object \n",
            " 27  Survival_Status          89945 non-null  object \n",
            " 28  Recurrence               89945 non-null  object \n",
            " 29  Time_to_Recurrence       89945 non-null  int64  \n",
            "dtypes: float64(1), int64(3), object(26)\n",
            "memory usage: 20.6+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1-4** Goal is to Confirm patient‑level rows, key clinical variables (e.g., diagnosis, stage, treatment, outcome), and data types."
      ],
      "metadata": {
        "id": "86WFbJE4f0sF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#4** focuses on inspecting the structure and contents of your dataset to ensure it loaded correctly and to understand what you’re working with before any cleaning or modeling begins. By displaying the first few rows and reviewing the dataset’s dimensions, column names, and data types, you gain an immediate sense of variable formats, potential missing values, and the overall shape of the data. This early exploration helps you identify issues such as inconsistent categories, incorrect data types, or unexpected values, setting the stage for a clean and reliable preprocessing workflow."
      ],
      "metadata": {
        "id": "PtF0NCfIm9_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#5 Assess Missing Data Across Variables\n",
        "missing_counts = df.isnull().sum().sort_values(ascending=False)\n",
        "print(missing_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmTb0R8ie3Cl",
        "outputId": "e389adbe-d748-49af-895b-372920fbd449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient_ID                 0\n",
            "Age                        0\n",
            "Gender                     0\n",
            "Race                       0\n",
            "Region                     0\n",
            "Urban_or_Rural             0\n",
            "Socioeconomic_Status       0\n",
            "Family_History             0\n",
            "Previous_Cancer_History    0\n",
            "Stage_at_Diagnosis         0\n",
            "Tumor_Aggressiveness       0\n",
            "Colonoscopy_Access         0\n",
            "Screening_Regularity       0\n",
            "Diet_Type                  0\n",
            "BMI                        0\n",
            "Physical_Activity_Level    0\n",
            "Smoking_Status             0\n",
            "Alcohol_Consumption        0\n",
            "Red_Meat_Consumption       0\n",
            "Fiber_Consumption          0\n",
            "Insurance_Coverage         0\n",
            "Time_to_Diagnosis          0\n",
            "Treatment_Access           0\n",
            "Chemotherapy_Received      0\n",
            "Radiotherapy_Received      0\n",
            "Surgery_Received           0\n",
            "Follow_Up_Adherence        0\n",
            "Survival_Status            0\n",
            "Recurrence                 0\n",
            "Time_to_Recurrence         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#5** evaluates the completeness of your dataset by calculating how many missing values appear in each column. The code identifies null entries, sums them for every variable, and sorts the results so that any columns with the highest number of missing values would appear first. This quick check helps you confirm data quality before moving into preprocessing or modeling. In this case, every column shows a count of zero, meaning the dataset is fully complete with no missing entries to address."
      ],
      "metadata": {
        "id": "UQ0lN2W4opbi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#5**. Quantify and review missing values"
      ],
      "metadata": {
        "id": "V6KSpOvVE0QB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What to look for:\n",
        "\n",
        "Clinically critical variables: e.g., tumor stage, grade, biomarkers, outcome (survival/recurrence).\n",
        "\n",
        "High missingness: candidates for dropping or special handling (e.g., >40%)."
      ],
      "metadata": {
        "id": "_noXYwyNEtb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#6 Filter Out Low‑Completeness Variables\n",
        "threshold = 0.4\n",
        "cols_to_drop = missing_counts[missing_counts > threshold * len(df)].index\n",
        "print(\"Dropping columns:\", list(cols_to_drop))\n",
        "\n",
        "df = df.drop(columns=cols_to_drop)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSGbrT_DhWN1",
        "outputId": "45000a0c-831c-48d7-b50b-cfa8d7ef40f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropping columns: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#6** focuses on evaluating whether any columns in the dataset should be removed due to excessive missing data. By defining a threshold of 40%, the code identifies columns where more than 40% of their values are missing and prepares them for removal. This protects the integrity of your analysis by ensuring that variables with too much incomplete information don’t distort downstream modeling or require heavy imputation. In this case, the output shows an empty list, meaning no columns exceeded the threshold and the dataset remains fully intact."
      ],
      "metadata": {
        "id": "QeJISVjspFMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#7 Standardize and Encode Categorical Variables\n",
        "\n",
        "if 'Biomarker_Status' in df.columns:\n",
        "    df['Biomarker_Status'] = (\n",
        "        df['Biomarker_Status']\n",
        "        .str.upper()\n",
        "        .map({'POSITIVE': 1, 'NEGATIVE': 0})\n",
        "    )\n",
        "\n",
        "# Example: standardize a sex column\n",
        "if 'Sex' in df.columns:\n",
        "    df['Sex'] = df['Sex'].str.strip().str.upper()\n"
      ],
      "metadata": {
        "id": "TwydkputhWPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#7** focuses on cleaning and standardizing categorical variables so they are consistent and ready for modeling. The code checks whether certain columns exist—such as a binary biomarker status or a sex column—and then applies transformations to make their values uniform. For the biomarker example, the text values are converted to uppercase and mapped to numeric indicators (1 for positive, 0 for negative), which is essential for machine‑learning algorithms that require numeric inputs. For the sex column, whitespace is removed and values are standardized to uppercase, ensuring consistent categories and preventing subtle formatting issues from causing errors later in the pipeline."
      ],
      "metadata": {
        "id": "bBC6CUiipkuE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#7**. Standardize and encode key clinical variables\n",
        "Adapt this to your actual column names (examples below):\n",
        "**Goal:** Make clinically important variables consistent and model ready."
      ],
      "metadata": {
        "id": "uj7R8VeuFrks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#8 Identify Numeric and Categorical Feature Groups\n",
        "\n",
        "numeric_cols = df.select_dtypes(include=['number']).columns\n",
        "categorical_cols = df.select_dtypes(exclude=['number']).columns\n",
        "\n",
        "print(\"Numeric columns:\", list(numeric_cols))\n",
        "print(\"Categorical columns:\", list(categorical_cols))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsQtpDS3G3MI",
        "outputId": "ea158cd7-90ec-44a0-829b-20ad5d3d2b1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numeric columns: ['Patient_ID', 'Age', 'BMI', 'Time_to_Recurrence']\n",
            "Categorical columns: ['Gender', 'Race', 'Region', 'Urban_or_Rural', 'Socioeconomic_Status', 'Family_History', 'Previous_Cancer_History', 'Stage_at_Diagnosis', 'Tumor_Aggressiveness', 'Colonoscopy_Access', 'Screening_Regularity', 'Diet_Type', 'Physical_Activity_Level', 'Smoking_Status', 'Alcohol_Consumption', 'Red_Meat_Consumption', 'Fiber_Consumption', 'Insurance_Coverage', 'Time_to_Diagnosis', 'Treatment_Access', 'Chemotherapy_Received', 'Radiotherapy_Received', 'Surgery_Received', 'Follow_Up_Adherence', 'Survival_Status', 'Recurrence']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#8** organizes your dataset by separating numeric and categorical columns, a foundational move that prepares the data for targeted preprocessing and modeling. By using select_dtypes, the code automatically identifies which variables contain numerical values and which contain non‑numeric, label‑based information. This distinction matters because numeric features often require scaling or normalization, while categorical features typically need encoding or grouping. Clearly defining these two groups early in the workflow keeps your pipeline clean, modular, and ready for the next transformation steps."
      ],
      "metadata": {
        "id": "1GVKSnOZqRh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#8** Reason: Numeric and categorical features usually need different imputation and encoding strategies."
      ],
      "metadata": {
        "id": "pnKf668fHT5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#9 Fill numeric columns with their mean (or median if preferred)\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n"
      ],
      "metadata": {
        "id": "IsYCtEn7G3eJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#9**. Impute missing values in numeric columns\n",
        "\n",
        "Optional. If you prefer median (often more robust in clinical data):\n",
        "Alternative: median imputation\n",
        "\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "**Clinical note:** For some variables (e.g., “Family history”), you might instead use a category like \"Unknown\" if that’s more interpretable.\n"
      ],
      "metadata": {
        "id": "vY9f6gM8HpRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#10. Deduplicate Patient-Level Records\n",
        "\n",
        "if 'Patient_ID' in df.columns:\n",
        "    df = df.drop_duplicates(subset=['Patient_ID'])\n",
        "else:\n",
        "    # If no explicit ID, you can still drop exact row duplicates\n",
        "    df = df.drop_duplicates()\n"
      ],
      "metadata": {
        "id": "jvsKr6BvG3fU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#10** Ensures that each patient appears only once in the dataset by removing duplicate records at the patient level. The code first checks whether a dedicated identifier such as Patient_ID exists; if it does, duplicates are removed based on that column so that every patient is uniquely represented. If no identifier is available, the fallback is to remove exact row‑level duplicates. This step protects the integrity of downstream analyses by preventing inflated sample sizes, repeated observations, or biased modeling results."
      ],
      "metadata": {
        "id": "7LRNr1j6H92R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#11. Validate Absence of Missing Data”\n",
        "# You want to see zeros (or only intentional missingness) across all columns before modeling.\n",
        "\n",
        "print(df.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6EhX1N9hJM7",
        "outputId": "068ec5e6-aea9-4cd9-bb27-06313bbc3d64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient_ID                 0\n",
            "Age                        0\n",
            "Gender                     0\n",
            "Race                       0\n",
            "Region                     0\n",
            "Urban_or_Rural             0\n",
            "Socioeconomic_Status       0\n",
            "Family_History             0\n",
            "Previous_Cancer_History    0\n",
            "Stage_at_Diagnosis         0\n",
            "Tumor_Aggressiveness       0\n",
            "Colonoscopy_Access         0\n",
            "Screening_Regularity       0\n",
            "Diet_Type                  0\n",
            "BMI                        0\n",
            "Physical_Activity_Level    0\n",
            "Smoking_Status             0\n",
            "Alcohol_Consumption        0\n",
            "Red_Meat_Consumption       0\n",
            "Fiber_Consumption          0\n",
            "Insurance_Coverage         0\n",
            "Time_to_Diagnosis          0\n",
            "Treatment_Access           0\n",
            "Chemotherapy_Received      0\n",
            "Radiotherapy_Received      0\n",
            "Surgery_Received           0\n",
            "Follow_Up_Adherence        0\n",
            "Survival_Status            0\n",
            "Recurrence                 0\n",
            "Time_to_Recurrence         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#11** confirms that all missing values in the dataset have been properly addressed before any modeling or statistical analysis begins. By printing the count of null values for every column, you get a quick diagnostic snapshot showing whether any variables still contain gaps that could distort model training, bias estimates, or break downstream algorithms. Seeing zeros across all fields indicates that the earlier cleaning steps—imputation, removal, or validation—were successful, and the dataset is now structurally complete and ready for feature engineering or modeling."
      ],
      "metadata": {
        "id": "YfvYeE6lIp49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#12. Export Final Cleaned Dataset\n",
        "\n",
        "output_path = '/content/drive/MyDrive/colorectal_cancer_prediction_cleaned_imputed.csv'\n",
        "df.to_csv(output_path, index=False)\n",
        "print(\"Cleaned dataset saved to:\", output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp6OH1G9hJZp",
        "outputId": "da53588d-ac56-4bb7-88dc-f017221d971d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned dataset saved to: /content/drive/MyDrive/colorectal_cancer_prediction_cleaned_imputed.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#12** finalizes the data‑cleaning workflow by exporting the fully processed dataset to long‑term storage so it can be reused for modeling, sharing, or documentation. After all cleaning, deduplication, and validation steps are complete, the code writes the DataFrame to a CSV file in the user’s Drive. This ensures the cleaned dataset is preserved in a stable, accessible location, preventing the need to rerun preprocessing and enabling consistent results across future analyses."
      ],
      "metadata": {
        "id": "Pb2xi5EyJET8"
      }
    }
  ]
}