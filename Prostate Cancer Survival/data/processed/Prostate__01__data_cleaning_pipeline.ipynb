{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Step1-4:** Mount Google Drive and load the dataset"
      ],
      "metadata": {
        "id": "PB2vBpJJIEM6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQlDMrxW5nmE",
        "outputId": "9e5e6404-fd77-42c7-c964-6ec2aee17b88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#1 Mount Google Drive for File Access\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#1** initializes access to your Google Drive within the Colab environment so that your notebook can read from and write to files stored there. By importing the google.colab.drive module and calling drive.mount('/content/drive'), Colab prompts you to authenticate your Google account. Once authenticated, your Drive becomes available at the /content/drive directory, allowing seamless loading of datasets, saving outputs, and maintaining a reproducible workflow across sessions."
      ],
      "metadata": {
        "id": "i6U_31PhyvnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2 Import Pandas Library\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "sRZBVN9DHp9C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#2** This step loads the pandas library, a core tool for data manipulation and analysis in Python. By importing it with the alias pd, you streamline your workflow and make future code more concise and readable. Pandas provides powerful data structures—especially DataFrames—that allow you to clean, transform, merge, summarize, and explore datasets efficiently. Importing it early in the workflow ensures that all subsequent steps can rely on its functionality without interruption."
      ],
      "metadata": {
        "id": "BcRS6m1LzT0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#3 Load Raw Dataset into DataFrame\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/prostate_cancer_prediction.csv')"
      ],
      "metadata": {
        "id": "OssyBcsfH0bc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#3** This step loads the raw prostate cancer dataset into your working environment so you can begin exploring, cleaning, and analyzing the data. Using pd.read_csv(), the code reads a CSV file stored in your Google Drive and converts it into a pandas DataFrame named df, which becomes the central object for all downstream processing. This step ensures that the dataset is accessible in memory, properly structured, and ready for any transformations, visualizations, or modeling tasks that follow."
      ],
      "metadata": {
        "id": "b2W_FiG70MG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#4 Inspect Raw Dataset Structure\n",
        "print(df.shape)      # dimensions\n",
        "print(df.head())     # preview first rows\n",
        "print(df.info())     # column types + missing values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbDEQjurHqiS",
        "outputId": "edcb05e8-d1c7-4c90-cbf1-759b710d758d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(27945, 30)\n",
            "   Patient_ID  Age Family_History Race_African_Ancestry  PSA_Level DRE_Result  \\\n",
            "0           1   78             No                   Yes       5.07     Normal   \n",
            "1           2   68             No                   Yes      10.24     Normal   \n",
            "2           3   54             No                    No      13.79     Normal   \n",
            "3           4   82             No                    No       8.03   Abnormal   \n",
            "4           5   47            Yes                    No       1.89     Normal   \n",
            "\n",
            "  Biopsy_Result Difficulty_Urinating Weak_Urine_Flow Blood_in_Urine  ...  \\\n",
            "0        Benign                   No              No             No  ...   \n",
            "1        Benign                  Yes              No             No  ...   \n",
            "2        Benign                   No              No             No  ...   \n",
            "3        Benign                   No              No             No  ...   \n",
            "4     Malignant                  Yes             Yes             No  ...   \n",
            "\n",
            "  Alcohol_Consumption Hypertension Diabetes Cholesterol_Level Screening_Age  \\\n",
            "0            Moderate           No       No            Normal            45   \n",
            "1                 Low           No       No              High            65   \n",
            "2                 Low           No       No            Normal            61   \n",
            "3                 Low           No       No            Normal            47   \n",
            "4            Moderate          Yes       No            Normal            72   \n",
            "\n",
            "  Follow_Up_Required Prostate_Volume Genetic_Risk_Factors  \\\n",
            "0                 No            46.0                   No   \n",
            "1                 No            78.2                   No   \n",
            "2                 No            21.1                   No   \n",
            "3                Yes            79.9                   No   \n",
            "4                 No            32.0                   No   \n",
            "\n",
            "   Previous_Cancer_History Early_Detection  \n",
            "0                       No             Yes  \n",
            "1                       No             Yes  \n",
            "2                       No             Yes  \n",
            "3                      Yes             Yes  \n",
            "4                       No             Yes  \n",
            "\n",
            "[5 rows x 30 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27945 entries, 0 to 27944\n",
            "Data columns (total 30 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   Patient_ID               27945 non-null  int64  \n",
            " 1   Age                      27945 non-null  int64  \n",
            " 2   Family_History           27945 non-null  object \n",
            " 3   Race_African_Ancestry    27945 non-null  object \n",
            " 4   PSA_Level                27945 non-null  float64\n",
            " 5   DRE_Result               27945 non-null  object \n",
            " 6   Biopsy_Result            27945 non-null  object \n",
            " 7   Difficulty_Urinating     27945 non-null  object \n",
            " 8   Weak_Urine_Flow          27945 non-null  object \n",
            " 9   Blood_in_Urine           27945 non-null  object \n",
            " 10  Pelvic_Pain              27945 non-null  object \n",
            " 11  Back_Pain                27945 non-null  object \n",
            " 12  Erectile_Dysfunction     27945 non-null  object \n",
            " 13  Cancer_Stage             27945 non-null  object \n",
            " 14  Treatment_Recommended    27945 non-null  object \n",
            " 15  Survival_5_Years         27945 non-null  object \n",
            " 16  Exercise_Regularly       27945 non-null  object \n",
            " 17  Healthy_Diet             27945 non-null  object \n",
            " 18  BMI                      27945 non-null  float64\n",
            " 19  Smoking_History          27945 non-null  object \n",
            " 20  Alcohol_Consumption      27945 non-null  object \n",
            " 21  Hypertension             27945 non-null  object \n",
            " 22  Diabetes                 27945 non-null  object \n",
            " 23  Cholesterol_Level        27945 non-null  object \n",
            " 24  Screening_Age            27945 non-null  int64  \n",
            " 25  Follow_Up_Required       27945 non-null  object \n",
            " 26  Prostate_Volume          27945 non-null  float64\n",
            " 27  Genetic_Risk_Factors     27945 non-null  object \n",
            " 28  Previous_Cancer_History  27945 non-null  object \n",
            " 29  Early_Detection          27945 non-null  object \n",
            "dtypes: float64(3), int64(3), object(24)\n",
            "memory usage: 6.4+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#4** This step performs an initial inspection of the raw dataset to understand its structure, size, and basic characteristics before any cleaning or preprocessing begins. By printing the DataFrame’s shape, previewing the first few rows, and displaying detailed metadata such as column names, data types, and non‑null counts, you gain an early sense of data quality, potential missing values, and the overall layout of the dataset. This early diagnostic pass helps you plan downstream cleaning steps, identify categorical vs. numerical features, and confirm that the dataset loaded correctly."
      ],
      "metadata": {
        "id": "wij_Wbqq1ytz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1-4** Goal: Confirm patient-level granularity, identify outcome variables (e.g., cancer status, Gleason score, survival/recurrence if present), and understand variable types."
      ],
      "metadata": {
        "id": "Oy5Ywp-PIQAB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step5-6:** Quantify and review missing values"
      ],
      "metadata": {
        "id": "RpK1mFMgIyQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#5 Check total missing values per column\n",
        "missing_counts = df.isnull().sum()\n",
        "print(missing_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo81upC5H0kq",
        "outputId": "b0090f05-e6fb-43a1-814e-fe7337d4f115"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient_ID                 0\n",
            "Age                        0\n",
            "Family_History             0\n",
            "Race_African_Ancestry      0\n",
            "PSA_Level                  0\n",
            "DRE_Result                 0\n",
            "Biopsy_Result              0\n",
            "Difficulty_Urinating       0\n",
            "Weak_Urine_Flow            0\n",
            "Blood_in_Urine             0\n",
            "Pelvic_Pain                0\n",
            "Back_Pain                  0\n",
            "Erectile_Dysfunction       0\n",
            "Cancer_Stage               0\n",
            "Treatment_Recommended      0\n",
            "Survival_5_Years           0\n",
            "Exercise_Regularly         0\n",
            "Healthy_Diet               0\n",
            "BMI                        0\n",
            "Smoking_History            0\n",
            "Alcohol_Consumption        0\n",
            "Hypertension               0\n",
            "Diabetes                   0\n",
            "Cholesterol_Level          0\n",
            "Screening_Age              0\n",
            "Follow_Up_Required         0\n",
            "Prostate_Volume            0\n",
            "Genetic_Risk_Factors       0\n",
            "Previous_Cancer_History    0\n",
            "Early_Detection            0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#5** This step evaluates the dataset for missing values, an essential early task in any data‑cleaning workflow. By using df.isnull().sum(), you compute the total number of null entries in each column, allowing you to quickly identify whether the dataset requires imputation, removal of incomplete rows, or additional preprocessing. In this case, the output shows zeros across all columns, confirming that the dataset is fully complete and does not require missing‑value handling—an ideal scenario that simplifies downstream analysis and modeling."
      ],
      "metadata": {
        "id": "fgb5DakW2UwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#6 Calculate Missingness Percentages\n",
        "missing_percent = (df.isnull().mean() * 100).round(2)\n",
        "print(missing_percent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jL4m_t4IirO",
        "outputId": "a0f28152-4f6f-4872-9952-57defff157ab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient_ID                 0.0\n",
            "Age                        0.0\n",
            "Family_History             0.0\n",
            "Race_African_Ancestry      0.0\n",
            "PSA_Level                  0.0\n",
            "DRE_Result                 0.0\n",
            "Biopsy_Result              0.0\n",
            "Difficulty_Urinating       0.0\n",
            "Weak_Urine_Flow            0.0\n",
            "Blood_in_Urine             0.0\n",
            "Pelvic_Pain                0.0\n",
            "Back_Pain                  0.0\n",
            "Erectile_Dysfunction       0.0\n",
            "Cancer_Stage               0.0\n",
            "Treatment_Recommended      0.0\n",
            "Survival_5_Years           0.0\n",
            "Exercise_Regularly         0.0\n",
            "Healthy_Diet               0.0\n",
            "BMI                        0.0\n",
            "Smoking_History            0.0\n",
            "Alcohol_Consumption        0.0\n",
            "Hypertension               0.0\n",
            "Diabetes                   0.0\n",
            "Cholesterol_Level          0.0\n",
            "Screening_Age              0.0\n",
            "Follow_Up_Required         0.0\n",
            "Prostate_Volume            0.0\n",
            "Genetic_Risk_Factors       0.0\n",
            "Previous_Cancer_History    0.0\n",
            "Early_Detection            0.0\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#6** This step provides an optional but more interpretable view of missingness by converting raw null counts into percentages. Instead of simply knowing whether a column has missing values, calculating the proportion of missing entries helps you understand the relative impact of missingness on each feature—especially useful in larger datasets. By computing the mean of the boolean null mask, multiplying by 100, and rounding to two decimals, you generate a clean, human‑readable summary. In this dataset, every column shows 0.0% missingness, confirming once again that the data is fully complete and requires no imputation or removal of incomplete records."
      ],
      "metadata": {
        "id": "x5Dac0ne25RG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step5-6:** Goal: Decide which variables are clinically essential (e.g., PSA, Gleason score, stage) and which may be dropped or imputed."
      ],
      "metadata": {
        "id": "TP-YfGvdJENr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7:** Drop columns with excessive missingness (optional, threshold-based)"
      ],
      "metadata": {
        "id": "WVspbHqQJWHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#7 Drop High‑Missingness Columns\n",
        "threshold = 40  # percent\n",
        "cols_to_drop = missing_percent[missing_percent > threshold].index\n",
        "print(\"Dropping columns:\", list(cols_to_drop))\n",
        "\n",
        "df = df.drop(columns=cols_to_drop)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9EUlLaGJLui",
        "outputId": "b27b583f-fdd8-48b7-aa45-2b265a63f5f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropping columns: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#7** This step demonstrates how to automatically remove columns that exceed a predefined threshold of missingness—in this case, more than 40%. By comparing each column’s missing‑value percentage to the threshold, the code identifies which features are too incomplete to be useful for analysis or modeling. These columns are collected into cols_to_drop and then removed from the DataFrame. In your dataset, the output shows an empty list, meaning no columns surpassed the threshold and therefore none were dropped. This confirms that the dataset is not only complete but also structurally stable for downstream preprocessing."
      ],
      "metadata": {
        "id": "6RTbjLQa4Klr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7:** Goal: Remove low-quality variables that are unlikely to be salvageable or clinically interpretable."
      ],
      "metadata": {
        "id": "J4xxTChVJZRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8:** Handle obvious duplicates (e.g., by patient ID)\n",
        "If your dataset has a patient identifier column (e.g., \"Patient_ID\", \"id\", \"patient_id\"), use it here. Adjust the column name accordingly."
      ],
      "metadata": {
        "id": "9ZhOBJZcJ01b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#8 Remove Duplicate Patient Records\n",
        "\n",
        "id_col = 'Patient_ID'\n",
        "\n",
        "if id_col in df.columns:\n",
        "    before = df.shape[0]\n",
        "    df = df.drop_duplicates(subset=[id_col])\n",
        "    after = df.shape[0]\n",
        "    print(f\"Removed {before - after} duplicate rows based on {id_col}\")\n",
        "else:\n",
        "    print(\"No explicit patient ID column found; consider checking duplicates on key clinical fields.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBhps7mvJL6K",
        "outputId": "a894bf80-2829-4047-d01c-dda64831d751"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed 0 duplicate rows based on Patient_ID\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#8** This step ensures that your dataset contains only unique patient records by identifying and removing duplicate rows based on a designated ID column. After defining the ID field (Patient_ID), the code checks whether that column exists in the DataFrame. If it does, it compares the number of rows before and after applying drop_duplicates to determine how many duplicate entries were removed. If the ID column is missing, the code provides a fallback message suggesting that duplicates be checked using key clinical variables instead. In your dataset, the output shows that 0 duplicate rows were removed, confirming that each patient record is already unique."
      ],
      "metadata": {
        "id": "cA7UAzu642h-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8:** Goal: Ensure each patient is represented once to avoid bias in modeling."
      ],
      "metadata": {
        "id": "bdees7p1KCuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 9:** Separate numeric and categorical columns"
      ],
      "metadata": {
        "id": "P8C0I2tAKXYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#9 Identify Numeric and Categorical Features\n",
        "\n",
        "numeric_cols = df.select_dtypes(include=['number']).columns\n",
        "categorical_cols = df.select_dtypes(exclude=['number']).columns\n",
        "\n",
        "print(\"Numeric columns:\", list(numeric_cols))\n",
        "print(\"Categorical columns:\", list(categorical_cols))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4bZW8jlJMER",
        "outputId": "e6e9e17b-c2e2-4fd8-b66a-8ff724c409c4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numeric columns: ['Patient_ID', 'Age', 'PSA_Level', 'BMI', 'Screening_Age', 'Prostate_Volume']\n",
            "Categorical columns: ['Family_History', 'Race_African_Ancestry', 'DRE_Result', 'Biopsy_Result', 'Difficulty_Urinating', 'Weak_Urine_Flow', 'Blood_in_Urine', 'Pelvic_Pain', 'Back_Pain', 'Erectile_Dysfunction', 'Cancer_Stage', 'Treatment_Recommended', 'Survival_5_Years', 'Exercise_Regularly', 'Healthy_Diet', 'Smoking_History', 'Alcohol_Consumption', 'Hypertension', 'Diabetes', 'Cholesterol_Level', 'Follow_Up_Required', 'Genetic_Risk_Factors', 'Previous_Cancer_History', 'Early_Detection']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#9** This step separates your dataset into numeric and categorical features, a foundational move for nearly all downstream preprocessing, modeling, and visualization tasks. By using select_dtypes, the code automatically identifies which columns contain numerical values (such as age, PSA level, or prostate volume) and which contain categorical information (such as family history or clinical symptoms). This separation allows you to apply the appropriate transformations to each group—like scaling numeric variables or encoding categorical ones—while maintaining a clean, organized workflow. The printed lists confirm exactly how the dataset is structured, giving you a clear map of your feature types before moving forward."
      ],
      "metadata": {
        "id": "AdOG5i1T5fED"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 9:** Goal: Prepare for different imputation strategies for numeric vs categorical variables."
      ],
      "metadata": {
        "id": "i8f-rk14KdEJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 10:** Impute numeric columns (e.g., with mean or median)\n",
        "For clinical data, median is often more robust than mean if there are outliers. You can choose either; here’s median:"
      ],
      "metadata": {
        "id": "5NiVO_-0K2AZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#10 Impute Numeric Columns with Median Values\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n"
      ],
      "metadata": {
        "id": "FA5C0zmkKuci"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#10** This step handles missing values in numeric columns by replacing any NaN entries with the median of each respective column. Median imputation is a widely used technique because it preserves the central tendency of the data while being robust to outliers—unlike the mean, which can be skewed by extreme values. By applying this operation to all numeric features at once, you ensure that the dataset remains complete and ready for modeling without introducing bias or distorting the underlying distributions. Even if your dataset currently has no missing numeric values, this step provides a reproducible safeguard for future datasets or updates."
      ],
      "metadata": {
        "id": "WStyca3Z6BmC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you prefer mean:\n",
        "\n",
        "-Alternative: fill numeric columns with mean\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n"
      ],
      "metadata": {
        "id": "N051cHUKLCiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 10:** Goal: Ensure all numeric features (e.g., PSA, age, lab values) are complete for modeling."
      ],
      "metadata": {
        "id": "YZjxiNsaK1-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#11 Impute Categorical Columns with Mode\n",
        "\n",
        "for col in categorical_cols:\n",
        "    if df[col].isnull().sum() > 0:\n",
        "        df[col] = df[col].fillna(df[col].mode()[0])\n"
      ],
      "metadata": {
        "id": "IZRBcf3DKut5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#11** This step imputes missing values in categorical columns by filling them with each column’s mode—the most frequently occurring category. Mode imputation is a common and practical approach because it preserves the dominant pattern within a feature without introducing unrealistic or synthetic categories. The loop checks each categorical column individually and only applies imputation if that column actually contains missing values, ensuring the process is efficient and minimally invasive. Even if your dataset currently has no missing categorical values, this step adds robustness and reproducibility for future datasets or updates."
      ],
      "metadata": {
        "id": "dx6S1-Pq6nLD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#11** Goal: Preserve the most common clinically plausible category (e.g., “Localized”, “Benign”, “Unknown”) rather than dropping rows."
      ],
      "metadata": {
        "id": "Wz0zZdGRjMO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 12:** (Optional) Encode key clinical categorical variables\n",
        "If you have a binary outcome like \"cancer_present\" or \"diagnosis\" with values such as \"Malignant\"/\"Benign\", you can encode it:\n",
        "\n",
        "Goal: Prepare clinically meaningful targets for prediction models."
      ],
      "metadata": {
        "id": "Ar_mLW41jgRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#12 Encode Binary Outcome Variable / Adjust 'Outcome' and value labels to match your dataset\n",
        "if 'Outcome' in df.columns:\n",
        "    df['Outcome_binary'] = df['Outcome'].str.upper().map({\n",
        "        'MALIGNANT': 1,\n",
        "        'BENIGN': 0\n",
        "    })\n",
        "    print(df['Outcome_binary'].value_counts(dropna=False))\n"
      ],
      "metadata": {
        "id": "IJzkyTGcjh1q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#12** This step converts a binary outcome column into a numerical format suitable for modeling by mapping text labels to numeric values. After confirming that the dataset contains a column named Outcome, the code standardizes its text to uppercase and then maps the two possible categories—such as MALIGNANT and BENIGN—to 1 and 0, respectively. This transformation is essential because most machine‑learning algorithms require numerical inputs and cannot directly interpret string‑based labels. The printed value counts provide a quick check to ensure the encoding worked correctly and that both classes are represented as expected."
      ],
      "metadata": {
        "id": "azc0lEQa7ui_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#13 Final Missing‑Value Audit\n",
        "print(df.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj0F1GIZj44y",
        "outputId": "a30daf24-56c6-412a-861f-d8a9078619d2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient_ID                 0\n",
            "Age                        0\n",
            "Family_History             0\n",
            "Race_African_Ancestry      0\n",
            "PSA_Level                  0\n",
            "DRE_Result                 0\n",
            "Biopsy_Result              0\n",
            "Difficulty_Urinating       0\n",
            "Weak_Urine_Flow            0\n",
            "Blood_in_Urine             0\n",
            "Pelvic_Pain                0\n",
            "Back_Pain                  0\n",
            "Erectile_Dysfunction       0\n",
            "Cancer_Stage               0\n",
            "Treatment_Recommended      0\n",
            "Survival_5_Years           0\n",
            "Exercise_Regularly         0\n",
            "Healthy_Diet               0\n",
            "BMI                        0\n",
            "Smoking_History            0\n",
            "Alcohol_Consumption        0\n",
            "Hypertension               0\n",
            "Diabetes                   0\n",
            "Cholesterol_Level          0\n",
            "Screening_Age              0\n",
            "Follow_Up_Required         0\n",
            "Prostate_Volume            0\n",
            "Genetic_Risk_Factors       0\n",
            "Previous_Cancer_History    0\n",
            "Early_Detection            0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#13** This step performs a final verification of missing values across the entire dataset after all earlier cleaning and imputation steps have been applied. By running df.isnull().sum(), you generate a complete count of null entries for every column, allowing you to confirm that no missing values remain and that the dataset is fully prepared for downstream modeling or feature engineering. The output shows zeros for every feature, indicating that your preprocessing pipeline has successfully produced a complete, analysis‑ready dataset."
      ],
      "metadata": {
        "id": "_0_ZZRDG8ZiM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 13:** Verify all missing values are handled\n",
        "You want to see zeros for all columns you plan to use in modeling."
      ],
      "metadata": {
        "id": "uvjo9K3JkHLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#14 Save Cleaned Dataset to Drive\n",
        "\n",
        "df.to_csv('/content/drive/MyDrive/prostate_cancer_prediction_cleaned_imputed.csv', index=False)\n",
        "print(\"Cleaned dataset saved to Drive.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC1LK4X4j5G-",
        "outputId": "855c4ecb-41e4-4e6b-9f41-35d9c8b84b2f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned dataset saved to Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#14** This step saves your fully cleaned and imputed dataset back to Google Drive, creating a permanent, versioned output that can be reused for modeling, sharing, or future analysis. By writing the DataFrame to a CSV file using df.to_csv(), you ensure that all preprocessing steps—such as missing‑value handling, deduplication, encoding, and type separation—are preserved in a stable, portable format. Saving the file without the index keeps the dataset tidy and consistent with typical machine‑learning workflows. The confirmation message provides immediate feedback that the export was successful."
      ],
      "metadata": {
        "id": "rejAncBU9EMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step#14:** If you’d like, you can paste a few lines of df.head() or df.info() from your actual prostate_cancer_prediction file, and we can tailor the cleaning logic to its exact columns (e.g., specific outcome, staging, PSA fields)."
      ],
      "metadata": {
        "id": "777oJ9Tck45c"
      }
    }
  ]
}