# -*- coding: utf-8 -*-
"""Prostate_scr/03_data_exploration

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Tdu68854zrBrR1sSKXRp-rDA1c5vOCXZ
"""

# 1. Initialize Analysis Environment and Core Libraries
# ----------------------------------------------------
import os
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

sns.set(style="whitegrid")
plt.rcParams["figure.figsize"] = (10, 6)

print("Environment initialized.")

"""**Step #1** sets up the core analysis environment by importing the foundational Python libraries used throughout the workflow—os for file handling, pandas for data manipulation, numpy for numerical operations, and seaborn/matplotlib for visualization. It also applies consistent plotting aesthetics by enabling Seaborn’s whitegrid style and defining a default figure size, ensuring that all subsequent visualizations share a clean, readable appearance. The step concludes with a confirmation message indicating that the environment is ready for analysis.

**(Why This Step Matters)**
This step matters because every analysis pipeline depends on a stable, predictable environment. By importing essential libraries and setting global visualization parameters upfront, you eliminate inconsistencies, reduce repetitive setup code, and guarantee that collaborators (or future you) can run the notebook without confusion or missing dependencies. It also ensures that plots generated later in the workflow are visually coherent and publication‑ready from the start.
"""

# 2. Connect to Google Drive for File Access
# ----------------------------------------------------
from google.colab import drive
drive.mount('/content/drive')

print("Google Drive mounted.")

"""**Step #2** connects your Colab notebook to Google Drive so the workflow can access datasets, save outputs, and maintain a consistent file structure across sessions. By importing the google.colab.drive module and mounting Drive at the /content/drive directory, this step establishes a secure link between the notebook and your stored files. Once mounted, all Drive folders become accessible just like a local filesystem, enabling seamless reading, writing, and organization of project assets.

**(Why This Step Matters)**
This step matters because Google Colab sessions are temporary—any files saved locally disappear once the session ends. Mounting Google Drive ensures that your datasets, models, logs, and generated outputs persist across sessions and remain organized in a stable location. It also supports reproducibility: collaborators can access the same directory structure, and you avoid accidental data loss or inconsistent file paths.
"""

# 3. Define Project File Paths and Output Structure
# ----------------------------------------------------
project_root = "/content/drive/MyDrive/prostate_cancer_prediction"

data_path = os.path.join(
    project_root, "data", "processed", "prostate_cancer_prediction_cleaned_imputed.csv"
)

print("Project paths set.")
print("Data path:", data_path)

"""**Step #3** establishes the project’s directory structure by defining the root folder for the prostate cancer prediction workflow and constructing the full path to the cleaned and imputed dataset. Using os.path.join ensures that paths are built reliably and remain portable across environments. This step concludes by printing the resolved paths, confirming that the notebook now knows exactly where the project lives and where to find the primary data file that will be used in subsequent analysis.

**(Why This Step Matters)**
This step matters because a well‑defined directory structure prevents confusion, broken paths, and inconsistent file handling—common issues that derail collaborative or long‑term projects. By centralizing the project root and constructing all paths from it, you ensure that every downstream step references files in a stable, predictable way. This also makes the workflow easier to share, easier to maintain, and far less prone to errors caused by hard‑coded or scattered file locations.
"""

# 4. Load Dataset and Inspect Structure
# ----------------------------------------------------
data_path = "/content/drive/MyDrive/prostate_cancer_prediction_cleaned_imputed.csv"
df = pd.read_csv(data_path)

print("Dataset loaded successfully.")
print("Shape:", df.shape)
print("Columns:", list(df.columns))

"""**Step #4** loads the cleaned and imputed prostate cancer dataset into memory using pd.read_csv, verifies that the file was successfully read, and immediately reports the dataset’s structure by printing its shape and listing all column names. This provides an instant snapshot of the dataset’s dimensions—27,945 rows and 30 columns—and confirms the presence of key variables such as Patient_ID, Age, Family_History, Race_African_Ancestry, PSA_Level, and DRE_Result. By surfacing this information upfront, the step ensures that the dataset is accessible, correctly formatted, and ready for downstream preprocessing and modeling.

**(Why This Step Matters)**
This step matters because loading the dataset correctly is the foundation of the entire analysis pipeline. Verifying the dataset’s shape and column names immediately catches issues such as missing files, incorrect paths, unexpected formatting changes, or incomplete preprocessing. Early inspection prevents downstream errors, ensures reproducibility, and gives you a quick mental model of the variables you’ll be working with—critical for both exploratory analysis and model development.
"""

# 5. Preview First Rows
# ----------------------------------------------------
df.head()

"""**Step #5** provides a visual preview of the dataset by displaying the first five rows using df.head(), allowing you to quickly inspect how the data appears in practice. This preview shows patient‑level information across clinical, demographic, and risk‑related variables—such as Age, Family_History, Race_African_Ancestry, PSA_Level, DRE_Result, Biopsy_Result, urinary symptoms, metabolic indicators, and early‑detection outcomes. Seeing these values in context helps confirm that the dataset is properly structured, that categorical and numerical fields look reasonable, and that the clinical variables align with expectations for a prostate cancer prediction workflow.

**(Why This Step Matters)**
This step matters because a quick visual scan of real data often reveals issues that summary statistics or metadata cannot—such as unexpected category labels, inconsistent formatting, implausible clinical values, or subtle preprocessing errors. It also helps you build intuition about the dataset’s clinical context, variable distributions, and potential modeling challenges. Before deeper exploration or feature engineering, confirming that the data “looks right” is essential for ensuring reliability and avoiding downstream mistakes.
"""

# 6. Check for Missing Values
# ----------------------------------------------------
missing_summary = df.isnull().sum().sort_values(ascending=False)
missing_summary.head(20)

"""**Step #6** evaluates the dataset for missing values by computing the number of null entries in each column, sorting them in descending order, and displaying the top results. The output shows that all examined columns—including key clinical, demographic, and lifestyle variables—contain zero missing values. This confirms that the dataset is fully populated and that earlier cleaning and imputation steps were successful. By validating completeness at this stage, the workflow ensures that downstream analyses, visualizations, and modeling will not be disrupted by unexpected gaps in the data.

**(Why This Step Matters)**
This step matters because missing data can significantly distort statistical summaries, bias machine‑learning models, and lead to incorrect clinical interpretations. Identifying missingness early allows you to confirm that the dataset is complete—or, in other contexts, to decide whether imputation, removal, or additional preprocessing is needed. In this case, confirming zero missing values provides confidence that the dataset is clean, consistent, and ready for reliable analysis.
"""

# 7. Generate Summary Statistics for Numeric Variables
# ----------------------------------------------------
df.describe()

"""**Step #7** generates descriptive statistics for all numeric variables in the dataset using df.describe(), providing a concise overview of their central tendencies, variability, and distribution ranges. The output summarizes key clinical and demographic features—such as Age, PSA_Level, BMI, Screening_Age, and Prostate_Volume—by reporting their mean, standard deviation, minimum and maximum values, and quartiles. This snapshot helps you quickly understand the scale and spread of each variable, identify potential outliers, and confirm that the values fall within clinically plausible ranges for a prostate‑cancer‑focused dataset.

**(Why This Step Matters)**
This step matters because descriptive statistics provide the first analytical lens into how the dataset behaves numerically. Understanding the distribution of key variables helps you detect anomalies, assess data quality, and anticipate modeling challenges such as skewed features or extreme values. These insights guide decisions about normalization, feature engineering, and model selection, ensuring that subsequent steps are grounded in a solid understanding of the dataset’s structure.
"""

# 8. Explore Categorical Variables
# ----------------------------------------------------
categorical_cols = df.select_dtypes(include=["object", "category"]).columns
df[categorical_cols].describe().T

"""**Step #8** explores all categorical variables in the dataset by selecting columns with object or category data types and generating descriptive statistics for each. The resulting table summarizes the number of unique categories, the most frequent value (the “top”), and its frequency across clinically relevant variables such as Family_History, DRE_Result, Biopsy_Result, Cancer_Stage, lifestyle factors, comorbidities, and early‑detection indicators. This overview provides a clear snapshot of how categorical features are distributed, highlighting dominant patterns—such as the prevalence of “No” responses in symptom‑related fields or the frequency of “Localized” cancer stage—helping you understand the structure and balance of key clinical attributes.

**(Why This Step Matters)**
This step matters because categorical variables often carry essential clinical meaning—such as disease stage, symptom presence, lifestyle risks, or treatment recommendations—and their distribution directly affects model behavior. Understanding category frequencies helps identify class imbalance, detect unexpected or rare categories, and guide decisions about encoding strategies for machine learning. It also ensures that the dataset’s categorical structure aligns with clinical expectations, reducing the risk of misinterpretation or biased modeling downstream.
"""

# 9. Visualize Target Variable Distribution
# ----------------------------------------------------
target_candidates = ["cancer_status", "diagnosis", "outcome", "survival_status"]

for col in target_candidates:
    if col in df.columns:
        sns.countplot(data=df, x=col)
        plt.title(f"Distribution of {col}")
        plt.show()

"""**Step #9** visualizes the distribution of potential target variables by looping through a list of candidate column names—such as "cancer_status", "diagnosis", "outcome", and "survival_status"—and generating a count plot for each one that exists in the dataset. For every matching column, the code produces a bar chart showing how frequently each category appears, allowing you to quickly assess class balance and identify whether the target variable is suitable for modeling. This automated approach ensures that any valid target column is immediately visualized without requiring manual plotting.

**(Why This Step Matters)**
This step matters because understanding the distribution of the target variable is essential for building reliable predictive models. Class imbalance—such as a target dominated by one category—can severely bias model performance and lead to misleading accuracy metrics. By visualizing these distributions early, you can determine whether resampling, reweighting, or alternative target selection is necessary. It also helps confirm that the dataset contains a meaningful and usable outcome variable before proceeding to modeling.
"""

# 10. Correlation Matrix for Numeric Features
# ----------------------------------------------------
numeric_cols = df.select_dtypes(include=["int64", "float64"]).columns

corr = df[numeric_cols].corr()

plt.figure(figsize=(14, 10))
sns.heatmap(corr, cmap="coolwarm", center=0)
plt.title("Correlation Matrix (Numeric Features)")
plt.show()

"""**Step #10** computes and visualizes the correlation matrix for all numeric features in the dataset. It begins by selecting numeric columns, calculating their pairwise correlations, and then displaying the results as a heatmap using Seaborn. This visualization highlights how strongly variables such as Age, PSA_Level, BMI, Screening_Age, and Prostate_Volume relate to one another. The color‑coded matrix makes it easy to spot strong positive or negative relationships, potential redundancies, and meaningful clinical patterns that may influence downstream modeling decisions.

**(Why This Step Matters)**
This step matters because correlation analysis helps identify multicollinearity, redundant features, and potential predictors. Highly correlated variables can distort model coefficients and reduce interpretability, while meaningful correlations may reveal clinically relevant relationships worth exploring further. By visualizing these patterns early, you gain insight into which features may require transformation, removal, or special handling before building predictive models.
"""

# 11. Distribution Plots for Key Clinical Variables
# ----------------------------------------------------
key_vars = ["age", "psa_level", "bmi"]

for col in key_vars:
    if col in df.columns:
        sns.histplot(df[col], kde=True)
        plt.title(f"Distribution of {col}")
        plt.show()

"""**Step #11** visualizes the distribution of key clinical variables—specifically age, PSA level, and BMI—by generating histograms with kernel density estimates (KDE). For each variable in the predefined list, the code checks whether the column exists in the dataset and then produces a distribution plot that reveals the shape, spread, and central tendencies of the data. These visualizations help you quickly assess whether each feature is normally distributed, skewed, multimodal, or contains unusual patterns that may influence modeling decisions or require preprocessing.

(Why This Step Matters)
This step matters because understanding the distribution of core clinical variables is essential for selecting appropriate modeling techniques and preprocessing strategies. Skewed or irregular distributions may require transformations, while multimodal patterns can signal underlying subgroups within the population. These plots also help validate data quality by revealing outliers, unexpected spikes, or truncated ranges. By examining these distributions early, you ensure that downstream modeling is grounded in a clear understanding of how each clinical variable behaves.


"""

# 12. Explore Predictor–Outcome Relationships
# ----------------------------------------------------
if "survival_status" in df.columns:
    sns.boxplot(data=df, x="survival_status", y="age")
    plt.title("Age vs Survival Status")
    plt.show()

    sns.boxplot(data=df, x="survival_status", y="psa_level")
    plt.title("PSA Level vs Survival Status")
    plt.show()

"""**Step #12** visually examines how key predictor variables—specifically age and psa_level—vary across categories of the target variable survival_status. Using boxplots, this step highlights differences in distribution, central tendency, and variability between survivors and non‑survivors. These visual comparisons help you quickly detect potential predictive patterns, such as whether older age or higher PSA levels are associated with poorer survival outcomes. This step serves as an early, intuitive check before moving into formal statistical testing or model building.

**(Why This Step Matters)**
Understanding how predictors relate to the target variable is essential for building a strong modeling pipeline. Visual diagnostics like boxplots help you identify which features may carry signal, which may require transformation, and which may not contribute meaningfully at all. They also reveal potential issues—such as skewness, extreme values, or overlapping distributions—that could influence model performance. In short, this step grounds your modeling decisions in clear, data‑driven intuition.
"""

# 13. Verify Dataset Uniqueness
# ----------------------------------------------------
duplicate_count = df.duplicated().sum()
duplicate_count

"""**Step #13** evaluates the dataset for duplicate rows to ensure that each observation represents a unique patient record. By using df.duplicated().sum(), this step counts how many rows appear more than once in the dataset. In the displayed output, the duplicate count is zero, confirming that the dataset contains no repeated entries. This quick diagnostic helps maintain data integrity before moving into more advanced preprocessing or modeling.

**(Why This Step Matters)**
Duplicate entries can significantly compromise the validity of a clinical research pipeline. In survival analysis or predictive modeling, repeated patient records can overweight certain outcomes, skew feature distributions, and lead to misleading model performance. Ensuring that the dataset contains only unique observations protects the integrity of downstream analyses and supports reproducible, trustworthy results.
"""

# 14. Review Dataset Variable Types
# ----------------------------------------------------
df.dtypes

"""**Step #14** reviews the data types of every column in the dataset to understand how each variable is currently represented—whether as integers, floats, or objects (typically categorical or text). This inspection helps you verify that numerical fields are correctly typed for analysis, that categorical variables are properly identified, and that no columns are mistakenly stored in an incompatible format. By examining the full list of data types, you establish a foundation for the cleaning, encoding, and modeling steps that follow.

**(Why This Step Matters)**
Accurate data types are essential for a reliable clinical research pipeline. Machine learning models require numerical inputs, statistical tests depend on correct variable classification, and preprocessing steps like one‑hot encoding or normalization only work when data types are properly defined. Misclassified columns—such as numeric values stored as text—can lead to errors, incorrect assumptions, or misleading results. By confirming data types at this stage, you prevent subtle issues from propagating through the workflow and ensure that each variable is handled appropriately.
"""

# 15. Export Exploration Artifacts
# ----------------------------------------------------
exploration_output_path = os.path.join(project_root, "data", "exploration")
os.makedirs(exploration_output_path, exist_ok=True)

missing_summary.to_csv(os.path.join(exploration_output_path, "missing_summary.csv"))
df.dtypes.to_frame("dtype").to_csv(os.path.join(exploration_output_path, "column_types.csv"))

print("Exploration summaries exported.")

"""**Step #15** saves key exploratory outputs—specifically the missing‑value summary and the column data‑type table—to organized CSV files within the project’s data/exploration directory. By creating the directory if it does not already exist and exporting both summaries, this step ensures that essential diagnostic information is preserved outside the notebook environment. These exported files become part of the project’s reproducible documentation, allowing collaborators, reviewers, or future analyses to reference the dataset’s structure and completeness without rerunning earlier code.

**(Why This Step Matters)**
Exporting exploration outputs is essential for maintaining a transparent and reproducible clinical research pipeline. Missing‑value patterns and column data types often guide critical preprocessing decisions, and preserving these summaries ensures that your reasoning remains traceable. It also supports collaboration—team members can review the dataset’s structure and completeness without needing direct access to the raw notebook. In regulated or publication‑oriented environments, having these artifacts stored as standalone files strengthens auditability and long‑term project integrity.
"""