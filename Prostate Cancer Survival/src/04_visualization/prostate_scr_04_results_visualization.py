# -*- coding: utf-8 -*-
"""Prostate_scr/04_results_visualization

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZmuuE7IEHhghXNKXpD4bgpIrVD7HMNKt
"""

# Step 1: Install Lifelines for Survival Analysis
!pip install lifelines --quiet

"""**Step #1** installs the lifelines Python package, which is a widely used library for performing survival analysis, including Kaplan–Meier estimation, Cox proportional hazards modeling, and time‑to‑event data handling. Because Google Colab and similar notebook environments reset their installed packages each session, this command ensures that all required survival‑analysis tools are available before running any downstream code. It is a one‑time setup step per runtime, guaranteeing that the environment is properly prepared for the rest of the workflow.

**(Why This Step Matters)**
Survival analysis workflows depend heavily on specialized statistical tools, and lifelines provides the core functionality for estimating survival curves, fitting Cox models, and handling censored data. Installing it upfront prevents runtime errors, ensures reproducibility, and establishes a consistent computational environment—especially important in cloud‑based notebooks where packages do not persist across sessions.
"""

# Step 2: Mount Google Drive for File Access
from google.colab import drive
drive.mount('/content/drive')

"""**Step #2** mounts your Google Drive into the Colab environment so that your notebook can directly access datasets, scripts, models, and output folders stored in Drive. When executed, this command creates a secure connection between Colab’s temporary runtime and your persistent Drive storage, allowing you to load files, save results, and maintain continuity across sessions. If the drive is already mounted, Colab simply acknowledges the existing connection, ensuring smooth access without interruption.

**(Why This Step Matters)**
Google Colab runtimes are temporary and do not store files permanently, so mounting Google Drive provides the stable, persistent storage needed for reproducible research. Without this step, you wouldn’t be able to reliably access your datasets, save model outputs, or maintain versioned files across sessions. Mounting Drive ensures that your workflow remains organized, consistent, and fully integrated with your long‑term storage.
"""

# Step 3: Define Paths and Load Dataset

import os
import pandas as pd

# Adjust this to your actual folder structure in Drive
BASE_DIR = "/content/drive/MyDrive"
DATA_PATH = os.path.join(BASE_DIR, "prostate_cancer_prediction_cleaned_imputed.csv")

df = pd.read_csv(DATA_PATH)

print("Shape:", df.shape)
df.head()

"""**Step #3** establishes the file paths for your project and loads the cleaned, imputed prostate cancer dataset into a pandas DataFrame. By defining a base directory and constructing the full path to the CSV file, this step ensures that your workflow remains organized, reproducible, and adaptable to different folder structures. Once the dataset is read, the code prints its shape and displays the first few rows, giving you an immediate sense of the dataset’s size, structure, and variable types before moving into preprocessing or modeling.

**(Why This Step Matters)**
Every downstream step—cleaning, feature engineering, modeling, evaluation—depends on having the correct dataset loaded in a consistent and reproducible way. Explicitly defining paths prevents errors caused by hard‑coded or inconsistent file locations, especially when collaborating or switching environments. The initial inspection ensures that the dataset is intact, properly formatted, and ready for analysis, reducing the risk of silent failures later in the pipeline.
"""

# Step 4: Perform Clinical Data Integrity Checks

# Basic info
df.info()

# Summary statistics for continuous variables
df.describe()

# Event counts (adapt 'event' to your actual event column)
# Example: 1 = event (e.g., progression/death), 0 = censored
event_col = "event"   # <-- CHANGE to your column
if event_col in df.columns:
    print(df[event_col].value_counts(dropna=False))

"""**Step #4** performs a set of quick clinical sanity checks to verify that the dataset is structurally sound and clinically coherent before deeper preprocessing or modeling. It begins by displaying the dataset’s full schema using df.info(), confirming the number of entries, column names, data types, and presence of missing values. It then generates summary statistics for continuous variables with df.describe(), providing an early look at ranges, central tendencies, and potential outliers. Finally, it includes a placeholder for counting event occurrences (e.g., malignant vs. benign outcomes), ensuring that the target variable is correctly populated and balanced. Together, these checks validate that the dataset is loaded correctly and behaves as expected from a clinical standpoint.

**(Why This Step Matters)**
Early sanity checks prevent downstream errors by catching structural or clinical inconsistencies before they propagate into modeling. In clinical prediction workflows, even small issues—such as mislabeled columns, unexpected missingness, or implausible values—can distort model performance or lead to misleading conclusions. By validating the dataset at this stage, you ensure that subsequent preprocessing, feature engineering, and modeling steps are built on a reliable foundation.
"""

# Step 5: Define Survival Analysis Variables

# CHANGE THESE to match your dataset
time_col = "Age"   # Using Age as the duration
event_col = "Survival_5_Years"          # Using Survival_5_Years as the event indicator

# Convert 'Survival_5_Years' to binary event indicator: 1 for 'No' (event), 0 for 'Yes' (censored)
df['event_indicator'] = df[event_col].apply(lambda x: 1 if x == 'No' else 0)
event_col = 'event_indicator'

# Optional grouping variable (e.g., risk group, treatment arm)
# Set to None if you don't have one
group_col = "Cancer_Stage"     # e.g., "Low", "Intermediate", "High"
if group_col not in df.columns:
    group_col = None

# Keep only rows with non-missing survival info
surv_df = df.dropna(subset=[time_col, event_col])
print("Survival analysis N:", surv_df.shape[0])
surv_df[[time_col, event_col] + ([group_col] if group_col else [])].head()

"""**Step #5** defines the key variables required for survival analysis by specifying the time‑to‑event column, converting the event indicator into a binary format, and optionally selecting a grouping variable such as cancer stage. It begins by identifying the duration variable (Age) and the event variable (Survival_5_Years), then transforms the event column into a numerical indicator where 1 represents an event (e.g., not surviving five years) and 0 represents censoring. The step also checks whether a grouping variable exists—useful for stratified survival curves or subgroup comparisons—and filters the dataset to include only rows with complete survival information. The resulting surv_df provides a clean, analysis‑ready subset tailored for Kaplan–Meier estimation or Cox modeling.

**(Why This Step Matters)**
Survival analysis requires clearly defined and properly formatted time and event variables. If these variables are inconsistent, non‑numeric, or incomplete, survival models will fail or produce misleading results. Converting the event indicator to binary ensures compatibility with statistical libraries, while selecting a grouping variable enables clinically meaningful comparisons across subpopulations. Filtering for complete cases prevents errors and ensures that the survival estimates reflect accurate, interpretable patient trajectories.
"""

# Step 6: Generate Overall Kaplan–Meier Survival Curve

import matplotlib.pyplot as plt
from lifelines import KaplanMeierFitter

kmf = KaplanMeierFitter()

T = surv_df[time_col]
E = surv_df[event_col]

kmf.fit(T, event_observed=E, label="Overall")

plt.figure(figsize=(7, 5))
kmf.plot(ci_show=True)
plt.title("Kaplan–Meier Survival Curve (Overall)")
plt.xlabel("Time")
plt.ylabel("Survival probability")
plt.grid(alpha=0.3)
plt.show()

"""**Step #6** generates the overall Kaplan–Meier survival curve, providing a non‑parametric estimate of survival probability over time for the entire cohort. Using the KaplanMeierFitter from the lifelines library, the step fits the model using the previously defined time‑to‑event (T) and event indicator (E) variables. It then plots the survival function with confidence intervals, offering a clear visual representation of how survival probability declines across the observed time span. This plot serves as the foundational survival analysis output, giving an immediate, intuitive understanding of the cohort’s overall survival pattern.

**(Why This Step Matters)**
The Kaplan–Meier curve is the cornerstone of survival analysis, offering a transparent, assumption‑free view of how survival changes over time. It allows clinicians and researchers to quickly assess overall prognosis, identify periods of rapid decline, and compare survival patterns across subgroups in later steps. Establishing this baseline curve is essential before moving on to stratified analyses or more complex modeling such as Cox proportional hazards.
"""

# Step 7: Generate Kaplan–Meier Curves by Clinical Subgroup

if group_col:
    plt.figure(figsize=(8, 6))
    for name, group in surv_df.groupby(group_col):
        kmf_group = KaplanMeierFitter()
        kmf_group.fit(group[time_col], event_observed=group[event_col], label=str(name))
        kmf_group.plot(ci_show=False)

    plt.title(f"Kaplan–Meier Curves by {group_col}")
    plt.xlabel("Time")
    plt.ylabel("Survival probability")
    plt.legend(title=group_col)
    plt.grid(alpha=0.3)
    plt.show()
else:
    print("No group_col defined; skipping grouped KM plot.")

"""**Step #7** generates Kaplan–Meier survival curves stratified by a clinical subgroup—in this case, Cancer_Stage—to compare survival patterns across different patient categories. The code loops through each stage (such as Advanced, Localized, and Metastatic), fits a separate Kaplan–Meier model for each subgroup, and plots all curves on the same axes. This produces a clear visual comparison of how survival probability changes over time for each clinical group, highlighting differences in prognosis and disease severity. The resulting figure provides an intuitive, side‑by‑side view of subgroup survival trajectories.

**(Why This Step Matters)**
Stratified Kaplan–Meier curves reveal clinically meaningful differences in survival across patient subgroups. They help identify high‑risk categories, evaluate disease severity, and guide clinical interpretation before more advanced modeling. Without this step, important subgroup differences—such as poorer survival in metastatic disease—would remain hidden in the overall curve, limiting the depth and accuracy of the analysis.
"""

# Step 8: Fit Cox Model and Compute Hazard Ratios

from lifelines import CoxPHFitter

# Choose covariates relevant for prostate cancer (adapt to your dataset)
# Example placeholders: age, psa, gleason_score, treatment
candidate_covariates = [
    "age",
    "psa",
    "gleason_score",
    "treatment"  # categorical; lifelines will one-hot encode if object dtype
]

covariates = [c for c in candidate_covariates if c in surv_df.columns]
print("Using covariates:", covariates)

cox_df = surv_df[[time_col, event_col] + covariates].dropna()

cph = CoxPHFitter()
cph.fit(cox_df, duration_col=time_col, event_col=event_col)

# Summary with hazard ratios (exp(coef))
cph_summary = cph.summary.copy()
cph_summary["HR"] = cph_summary["exp(coef)"]
cph_summary["HR_lower_95"] = cph_summary["exp(coef) lower 95%"]
cph_summary["HR_upper_95"] = cph_summary["exp(coef) upper 95%"]

cph_summary[["HR", "HR_lower_95", "HR_upper_95", "p"]]

"""**Step #8** fits a Cox proportional hazards model to estimate how selected clinical covariates influence the hazard of experiencing the event of interest. The step begins by defining a list of candidate predictors—such as age, PSA level, Gleason score, or treatment—and then filters this list to include only variables actually present in the dataset. After constructing a clean modeling DataFrame with the time, event, and covariate columns, the Cox model is fitted using the lifelines library. The resulting summary table includes hazard ratios and their 95% confidence intervals, allowing you to quantify how each covariate affects risk over time. Even if no covariates are available (as shown in the output), the structure prepares the workflow for proper multivariable survival modeling.

**(Why This Step Matters)**
The Cox proportional hazards model is the backbone of multivariable survival analysis, allowing you to quantify how different clinical factors independently influence risk over time. Hazard ratios provide interpretable effect sizes—showing whether a covariate increases, decreases, or has no meaningful impact on hazard. Without this step, the analysis would rely solely on unadjusted survival curves, which cannot account for confounding or interactions between variables. This step transforms the workflow from descriptive visualization into rigorous statistical modeling.
"""

# Step 9: Visualize Hazard Ratios with Forest Plot

import numpy as np

hr = cph_summary["HR"]
hr_lower = cph_summary["HR_lower_95"]
hr_upper = cph_summary["HR_upper_95"]
variables = cph_summary.index

plt.figure(figsize=(7, 0.5 * len(variables) + 2))

y_pos = np.arange(len(variables))

plt.errorbar(
    hr,
    y_pos,
    xerr=[hr - hr_lower, hr_upper - hr],
    fmt="o",
    color="black",
    ecolor="gray",
    capsize=4
)

plt.axvline(1.0, color="red", linestyle="--", label="HR = 1")
plt.yticks(y_pos, variables)
plt.xlabel("Hazard ratio (log scale)")
plt.xscale("log")
plt.title("Cox Model Hazard Ratios")
plt.grid(axis="x", alpha=0.3)
plt.legend()
plt.tight_layout()
plt.show()

"""**Step #9** creates a forest plot to visually display the hazard ratios and their 95% confidence intervals from the Cox proportional hazards model. After extracting the hazard ratios, lower bounds, upper bounds, and variable names from the model summary, the step constructs a horizontal plot where each covariate is represented by a point estimate and an error bar. A vertical reference line at HR = 1 helps distinguish risk‑increasing variables (HR > 1) from risk‑reducing variables (HR < 1). Even if the model currently has no covariates (as shown in the image), the structure of this step ensures that once covariates are included, the forest plot will provide a clear, interpretable visual summary of effect sizes.

**(Why This Step Matters)**
Forest plots are one of the most effective ways to interpret Cox model results because they present effect sizes and uncertainty in a single, intuitive visualization. They allow clinicians and researchers to quickly identify which variables meaningfully increase or decrease risk, assess the precision of estimates, and compare covariates side‑by‑side. Without this step, interpreting hazard ratios would rely solely on tables, which are less accessible and more prone to misinterpretation.
"""